{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7be88a8-702a-452a-a1c5-64ac7c69f206",
   "metadata": {},
   "source": [
    "# Content Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082bc7c3-2519-4302-812b-9ccc74947ae8",
   "metadata": {},
   "source": [
    "Orchestration also supports content filtering to moderate input and output. For each, multiple filters can be applied that remove harmful content from texts. Depending on the filter, sensitivity of various types can be configured."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712a76c2-cea5-4d27-9450-8e9e5abc6c9b",
   "metadata": {},
   "source": [
    "## Input Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5f0ed1-1e3e-4cbc-b1c3-c2250c7efd62",
   "metadata": {},
   "source": [
    "Input filtering is handy for blocking out harmful content form e.g. user input. To make use of input filtering we first up need to define a basic pipeline again. We use a simple prompt template, that just passes text provided as a parameter to an LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec261164-7bf2-4976-8419-4ceee9a246cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.models.llm import LLM\n",
    "from gen_ai_hub.orchestration.models.message import SystemMessage, UserMessage\n",
    "from gen_ai_hub.orchestration.models.template import Template, TemplateValue\n",
    "\n",
    "llm = LLM(\n",
    "    name=\"gemini-1.5-flash\",\n",
    "    version=\"latest\",\n",
    "    parameters={\"max_tokens\": 256, \"temperature\": 0.2},\n",
    ")\n",
    "\n",
    "template = Template(messages=[UserMessage(\"{{?text}}\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68548f9a-f6bd-444c-8e79-4c81ad598784",
   "metadata": {},
   "source": [
    "Next up we will configure an AzureContentFilter using the corresponding SDK primitives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4357055f-d596-4f58-b348-fa5c5bae2a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.models.azure_content_filter import AzureContentFilter\n",
    "\n",
    "content_filter = AzureContentFilter(\n",
    "    hate=0,\n",
    "    sexual=0,\n",
    "    self_harm=0,\n",
    "    violence=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca2ed16-6049-4c1b-911c-cf7672800738",
   "metadata": {},
   "source": [
    "**Note:** The lower the sensitivity value the higher the sensitivity. Zero (0) corresponds to the highest degree of content moderation. For further information please check out: https://learn.microsoft.com/en-us/azure/ai-services/content-safety/concepts/harm-categories?tabs=warning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7ef7b2-9c8d-4e86-851c-0b85853d38be",
   "metadata": {},
   "source": [
    "Now that we have all modules defined, the only thing left to do is plugging everything together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53759219-6df3-41d0-8be0-9b4fd4bcc7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.service import OrchestrationService\n",
    "from gen_ai_hub.orchestration.models.config import OrchestrationConfig\n",
    "from gen_ai_hub.orchestration.models.content_filtering import ContentFiltering, InputFiltering\n",
    "\n",
    "config = OrchestrationConfig(\n",
    "    template=template,\n",
    "    llm=llm,\n",
    "    filtering=ContentFiltering(input_filtering=InputFiltering(filters=[\n",
    "        content_filter,\n",
    "    ])),\n",
    ")\n",
    "\n",
    "orchestration_service = OrchestrationService(\n",
    "    api_url=os.environ[\"AICORE_ORCHESTRATION_DEPLOYMENT_URL\"],\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a0f422-3610-4383-b6a1-ac82e9882d72",
   "metadata": {},
   "source": [
    "If the content filter detects a violation when performing an inference an error of type `OrchestrationError` will be raised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29d6513-1a63-4326-9dbb-0c6ead10e30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.exceptions import OrchestrationError\n",
    "\n",
    "try:\n",
    "    result = orchestration_service.run(\n",
    "        template_values=[\n",
    "            TemplateValue(\n",
    "                name=\"text\",\n",
    "                value=\"This is a hateful text!\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "except OrchestrationError as error:\n",
    "    print(error.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aca10a5-b9d3-4c02-ac91-0b1c6c2eb009",
   "metadata": {},
   "source": [
    "The filter can be cleared by adjusting the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a531ce-5954-476f-8b49-af4cd5cd28a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = orchestration_service.run(\n",
    "    template_values=[\n",
    "        TemplateValue(\n",
    "            name=\"text\",\n",
    "            value=\"This is a peaceful text!\",\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "print(result.orchestration_result.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b2cd93-5e89-497e-892c-a8f9d3c2f759",
   "metadata": {},
   "source": [
    "## Output Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e56ffd-53a0-4914-a7f9-a2411a516064",
   "metadata": {},
   "source": [
    "Similarly, also LLM output can be filtered. We will just use our already created filter and apply it to the LLM output within the configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf0b75f-517e-49e6-a9a2-af20140b40c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "orchestration_service.config.output_filters = [content_filter]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75acc334-0cec-4311-b3bf-0964f0b0ec5e",
   "metadata": {},
   "source": [
    "Now let's try out if the filter works by prompting for an inherently violent lyrics from Johann Wolfgang von Goethe. Even though the version recited by the LLM might differ from the most common version, it should contain some form of suggested violence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b47c472-7973-45c3-951a-aadc98f67c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = orchestration_service.stream(\n",
    "    template_values=[\n",
    "        TemplateValue(\n",
    "            name=\"text\",\n",
    "            value='Provide the lyrics of the ballad \"Erlkönig\" from Johann Wolfgang von Goethe in German and English.',\n",
    "        )\n",
    "    ],\n",
    "    stream_options={\n",
    "        'chunk_size': 1\n",
    "    }\n",
    ")\n",
    "\n",
    "for chunk in result:\n",
    "    print(chunk.orchestration_result.choices[0].delta.content, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97147b02-65ac-4c54-85d9-f4881f847d54",
   "metadata": {},
   "source": [
    "**Note:** The behavior will differ from the input filter. Instead of raising an error, the returned content will be empty."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ead618-db88-46b7-a278-635b732b0e31",
   "metadata": {},
   "source": [
    "Feel free to try around with AzureContentFilter settings. If you set sensitivity for violence to 4 you will be able to read the lyrics of Erlkönig."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d30dd10-bab1-4afd-964a-92707824faac",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f599416-cc0b-44eb-9412-cd6dd97e0663",
   "metadata": {},
   "source": [
    "In this exercise you learned how content filtering can be applied to input and output using orchestration. Rather than entirely removing data, some scenarios call for selectively redacting specific information, such as email addresses or phone numbers. Continue to [Exercise 3 - Data Masking](./ex3.ipynb) to find out how this can be achieved."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
