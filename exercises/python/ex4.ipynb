{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ae93e38-6452-483c-81eb-91c3d64246bc",
   "metadata": {},
   "source": [
    "# Orchestration Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5765115a-307b-453a-9fd4-222183564bf8",
   "metadata": {},
   "source": [
    "We will now combine templating and content filtering in a chatbot. Additionally we will make use of the orchestration services history capability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe29833-0b77-45cb-926a-ce371c99056a",
   "metadata": {},
   "source": [
    "We start with building the chatbot class. This class will be responsible for providing the template for the user query and managing the history. Note that the `chat` method uses the `history` parameter to send along the history to the orchestration service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2dc5f8-6e6f-4726-80bc-737a076bcfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from gen_ai_hub.orchestration.models.message import Message, SystemMessage, UserMessage, AssistantMessage\n",
    "from gen_ai_hub.orchestration.models.template import Template, TemplateValue\n",
    "from gen_ai_hub.orchestration.service import OrchestrationService\n",
    "\n",
    "\n",
    "class OrchestrationChatbot:\n",
    "    def __init__(self, orchestration_service: OrchestrationService):\n",
    "        self.service = orchestration_service\n",
    "        system_message = SystemMessage(\"You are a helpful chatbot assistant.\")\n",
    "        self.service.config.template = Template(\n",
    "            messages=[\n",
    "                system_message,\n",
    "                UserMessage(\"{{?user_query}}\"),\n",
    "            ],\n",
    "        )\n",
    "        self.history: List[Message] = [\n",
    "            system_message,\n",
    "        ]\n",
    "\n",
    "    def chat(self, user_input):\n",
    "        response = self.service.stream(\n",
    "            template_values=[\n",
    "                TemplateValue(name=\"user_query\", value=user_input),\n",
    "            ],\n",
    "            history=self.history,\n",
    "            stream_options={\n",
    "                'chunk_size': 1\n",
    "            }\n",
    "        )\n",
    "\n",
    "        collected_response = \"\"\n",
    "        for chunk in response:\n",
    "            responseChunk = chunk.orchestration_result.choices[0].delta.content\n",
    "            collected_response += responseChunk\n",
    "            yield responseChunk\n",
    "\n",
    "        self.history.append(UserMessage(user_input))\n",
    "        self.history.append(AssistantMessage(collected_response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4df3010-e28c-4677-b09e-4747855ce346",
   "metadata": {},
   "source": [
    "Next up we will create an orchestration configuration. Next to the model parameter we also pass a content filter for input and output to ensure a nice conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b88013-88e0-4b09-904e-ee2d39bb881d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.models.config import OrchestrationConfig\n",
    "from gen_ai_hub.orchestration.models.azure_content_filter import AzureContentFilter\n",
    "from gen_ai_hub.orchestration.models.content_filtering import ContentFiltering, InputFiltering, OutputFiltering\n",
    "from gen_ai_hub.orchestration.models.llm import LLM\n",
    "\n",
    "content_filter = AzureContentFilter(\n",
    "    hate=0,\n",
    "    sexual=0,\n",
    "    self_harm=0,\n",
    "    violence=0,\n",
    ")\n",
    "config = OrchestrationConfig(\n",
    "    llm=LLM(name=\"gemini-1.5-flash\"),\n",
    "    template=None,\n",
    "    filtering=ContentFiltering(\n",
    "        input_filtering=InputFiltering(filters=[content_filter]),\n",
    "        output_filtering=OutputFiltering(filters=[content_filter]),\n",
    "    )\n",
    ")\n",
    "\n",
    "orchestration_service = OrchestrationService(\n",
    "    api_url=os.environ[\"AICORE_ORCHESTRATION_DEPLOYMENT_URL\"],\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00e7648-742c-48dd-b97a-d5463388d152",
   "metadata": {},
   "source": [
    "Lets chat with our bot and test if it is able to recall a conversation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bccdf7a-f67a-4730-b206-d7b429ddbd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot = OrchestrationChatbot(orchestration_service=orchestration_service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3e6a6e-9a56-4158-9748-21ca13f34126",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chatPart in bot.chat(\"How are you?\"):\n",
    "    print(chatPart, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae3fc17-5d36-48e7-847a-67be6fc402b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chatPart in bot.chat(\"What's the weather like today?\"):\n",
    "    print(chatPart, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fa8a0b-319c-4c1d-9f35-a8aded75bf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chatPart in bot.chat(\"Can you remember what I first asked you?\"):\n",
    "    print(chatPart, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b3a473-69c2-4276-9db4-608791aa5305",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chatPart in bot.chat(\"Write me a long poem about the content of our conversation.\"):\n",
    "    print(chatPart, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db711813-490e-4021-ad92-bca3f26ef0c1",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3497c99b-176d-4307-ba01-f7bbcb708411",
   "metadata": {},
   "source": [
    "In this exercise you got hands-on experience on how to use orchestration in complex scenarios. This exercise concludes the SAP generative AI hub SDK (Python) track. Feel free to further explore the orchestration capabilities using this SDK or checkout the [SAP Cloud SDK for AI (JavaScript)](https://github.com/SAP-samples/teched2024-AI180/blob/main/exercises/javascript/README.md) track."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
